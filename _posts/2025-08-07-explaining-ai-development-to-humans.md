---
layout: post
title: "Explaining AI Development to Humans: Programming with Natural Language"
date: 2025-08-07 00:09:00 -0700
categories: [AI Development, User Experience]
tags: [natural-language-programming, mcp-server-setup, sagemath-integration, agent-communication, task-tool-delegation, matrix-neo-learning, armored-officer-programming, 16000-lines-rust, game-balance-analyst-tutorial, scotty-star-trek-computer]
---

Let me see if I can grab a screen shot. So, have you interacted with one of the chat models before? This is very similar, especially with how you are interacting with them, which is English text via a field where you enter the prompt. Tools like this give the models the ability to use tools on your system. So they can read a file, edit a file, or run certain commands, which you give them permission to do. This tool I am using now runs inside a terminal window and has a view in most of the window that is the text being generated by our interactions or it running tools. Then at the bottom is a little area where I can type something to it.

It is pretty much programming a computer using natural language.

Here is a screenshot of my terminal as it is setting up an mcp server for the ability to use SageMath, which is a collection of math software put together by people.

![SageMath work](/assets/img/posts/2025-08-07/sage.jpeg)

So you can see a little bit above the middle where I am telling it to look at the files that another version of it edited on my other computer that begins with a '>', and down at the very bottom is where I type to it.

A lot of communication happens through files, or at least information is kept in files so they can access it. Usually, there will be a file that talks about the last thing that was done and what the next thing is. Or I can talk to it, and we decide on a plan for something. It has a todo list tool and will create a list of tasks to accomplish whatever we want done. Then it will either do the task, or it talks to another tool that is part of this, called the task tool, and tells it to create an agent. The agent is basically the same thing as the one I spend my time talking to, just that he gets his own memory and his own special prompt, and he and I cannot converse, usually, like I can with the main model. Even the main model can't talk to it like it does to me. It has to communicate with it through the task tool. So it is like it sends a letter to the post office addressed to the agent, then the letter gets delivered, the agent reads it, does the task, then sends a letter back to the post office, who then delivers the message to the main model.

The model is very capable at many things, and the prompt it has can focus its abilities. So I can tune an agent for a particular task to do something, kind of like if it was Neo in the Matrix learning Kung Fu. A lot of the above has been me trying to see how far I can push that and whether it will eventually break. I mean, a retired armored army officer that can program was sitting there writing little bot programs in their little fake bot programming language they came up with for the game. And it worked, lol. 

The block areas above where we chat are me both paraphrasing it and making light of the whole thing, but the gist of it is true, and the main model is communicating to me in English like I do with it. So the part where it got confused because it asked the simulation-designer for a pitch document, and the result that came back that was talking about a game jam is true, and he literally said 'something must have gone wrong. I asked for a pitch document, and it was talking about a game jam'. 

So they know how to do things because of these huge models, like program or apparently do math using cuda on my gpu. And I can sit here like a project manager handing tasks to the main model by typing natural language to it, and either it will complete the task or delegate it to an agent.

Doing that the past 13? days has resulted in a number of python programs for work completely rewritten and spruced up with features. A planetary science simulation with 16000+ lines of rust code, and now this knock off of Omega, which is already over 10000 lines of rust code. All created by these ai models. It is like I am Scotty in the Star Trek movie trying to talk to the computer, but the computer is actually listening.

Just to give another example of how nuts it all is. Just for giggles, I had it create that game balance analyst, and it did an evaluation of the math in the game. They've been working on updating the stuff based on a plan generated by that model's review. They are almost done, but it included implementing this crazy ass tutorial thing to teach players about resource management in the game. Because apparently, when you can code at 10,000 mph, you will put all sorts of things in there. I can't wait to see what it actually is.